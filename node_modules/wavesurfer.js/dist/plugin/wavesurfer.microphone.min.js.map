{"version":3,"file":"wavesurfer.microphone.min.js","mappings":";;;;;CAAA,SAA2CA,EAAMC,GAC1B,iBAAZC,SAA0C,iBAAXC,OACxCA,OAAOD,QAAUD,IACQ,mBAAXG,QAAyBA,OAAOC,IAC9CD,OAAO,aAAc,GAAIH,GACC,iBAAZC,QACdA,QAAoB,WAAID,KAExBD,EAAiB,WAAIA,EAAiB,YAAK,GAAIA,EAAiB,WAAc,WAAIC,KARpF,CASGK,MAAM,WACT,Y,4QC+BqBC,EAAAA,WAmBjB,WAAYC,EAAQC,GAAI,Y,4FAAA,SACpBC,KAAKF,OAASA,EACdE,KAAKC,WAAaF,EAElBC,KAAKE,QAAS,EACdF,KAAKG,QAAS,EACdH,KAAKI,QAAUJ,KAAKK,gBACpBL,KAAKM,qBAAuB,SAAAC,GAAC,OAAI,EAAKC,aAAaD,SAkCpBE,IAA3BC,UAAUC,eACVD,UAAUC,aAAe,SAMeF,IAAxCC,UAAUC,aAAaC,eACvBF,UAAUC,aAAaC,aAvCD,SACtBC,EACAC,EACAC,GAGA,IAAMH,EACFF,UAAUE,cACVF,UAAUM,oBACVN,UAAUO,iBACVP,UAAUQ,eAGd,OAAKN,EAOE,IAAIO,SAAQ,SAACL,EAAiBC,GACjCH,EAAaQ,KACTV,UACAG,EACAC,EACAC,MAXGI,QAAQE,OACX,IAAIC,MAAM,sDA0BtBtB,KAAKa,YAAcb,KAAKF,OAAOe,aAAe,CAC1CU,OAAO,EACPC,OAAO,GAEXxB,KAAKyB,WAAazB,KAAKF,OAAO2B,YAAc,KAC5CzB,KAAK0B,sBAAwB1B,KAAKF,OAAO4B,uBAAyB,EAClE1B,KAAK2B,uBAAyB3B,KAAKF,OAAO6B,wBAA0B,EAEpE3B,KAAK4B,kBAAoB,WAErB,EAAKC,WAAa,EAAK5B,WAAW6B,QAAQC,mB,4CAtElD,SAAcjC,GACV,MAAO,CACHkC,KAAM,aACNC,aAAWnC,IAAUA,EAAOmC,YAAYnC,EAAOmC,UAC/CnC,OAAQA,EACRoC,SAAUrC,O,qBAqElB,WACIG,KAAKC,WAAWkC,GAAG,kBAAmBnC,KAAK4B,mBACvC5B,KAAKC,WAAW6B,SAChB9B,KAAK4B,sB,qBAOb,WAGI5B,KAAKG,QAAS,EAEdH,KAAKC,WAAWmC,GAAG,kBAAmBpC,KAAK4B,mBAC3C5B,KAAKqC,S,mBAOT,WAAQ,WACJ3B,UAAUC,aACLC,aAAaZ,KAAKa,aAClByB,MAAK,SAAAC,GAAI,OAAI,EAAKC,UAAUD,MAC5BE,OAAM,SAAAF,GAAI,OAAI,EAAKG,YAAYH,Q,wBAMxC,WACSvC,KAAKE,QAKNF,KAAKG,QAAUH,KAAKG,OAEhBH,KAAKG,OACLH,KAAK2C,QAEL3C,KAAK4C,QART5C,KAAK6C,U,kBAgBb,WACI7C,KAAKG,QAAS,EAEdH,KAAK8C,Y,mBAMT,WACI9C,KAAKG,QAAS,EAIdH,KAAK+C,e,kBAOT,WACQ/C,KAAKE,SAELF,KAAKgD,aAGLhD,KAAKC,WAAWgD,W,wBAOxB,WACIjD,KAAKE,QAAS,EAGdF,KAAK+C,aAGD/C,KAAKkD,QAAUlD,KAAKkD,OAAOC,WAC3BnD,KAAKkD,OAAOC,YAAYC,SAAQ,SAAAF,GAAM,OAAIA,EAAOb,Y,qBAOzD,gBACwB5B,IAAhBT,KAAKkD,SAEwB,SAAzBlD,KAAKI,QAAQA,UACbJ,KAAKqD,iBAAmBrD,KAAK6B,WAAWyB,aACpCtD,KAAK0B,sBACL1B,KAAKyB,WACLzB,KAAK6B,WAAW0B,aAKxBvD,KAAKwD,kBAAoBxD,KAAK6B,WAAW4B,wBACrCzD,KAAKkD,QAGTlD,KAAK0D,aAAe1D,KAAK6B,WAAW8B,sBAChC3D,KAAKyB,WACLzB,KAAK0B,sBACL1B,KAAK2B,wBAET3B,KAAKwD,kBAAkBV,QAAQ9C,KAAK0D,cAEpC1D,KAAK0D,aAAaZ,QAAQ9C,KAAK6B,WAAW+B,aAC1C5D,KAAK0D,aAAaG,eAAiB7D,KAAKM,wB,wBAOhD,gBACmCG,IAA3BT,KAAKwD,mBACLxD,KAAKwD,kBAAkBT,kBAGDtC,IAAtBT,KAAK0D,eACL1D,KAAK0D,aAAaX,aAClB/C,KAAK0D,aAAaG,oBAAiBpD,QAGTA,IAA1BT,KAAKqD,mBACLrD,KAAKqD,sBAAmB5C,K,0BAShC,SAAaqD,GACT,IAAK9D,KAAKG,OAGN,GAFAH,KAAKC,WAAWgD,QAEa,SAAzBjD,KAAKI,QAAQA,QAAoB,CAGjC,IAAI2D,EAASC,EACb,IACID,EAAU,EACVC,EAAIC,KAAKC,IACLlE,KAAKqD,iBAAiBc,iBACtBL,EAAMM,YAAYD,kBAEtBJ,EAAUC,EACVD,IAEA/D,KAAKqD,iBACAgB,eAAeN,GACfO,IAAIR,EAAMM,YAAYC,eAAeN,IAG9C/D,KAAKC,WAAWsE,kBAAkBvE,KAAKqD,uBAEvCrD,KAAKC,WAAWsE,kBAAkBT,EAAMM,e,uBAUpD,SAAUlB,GACNlD,KAAKkD,OAASA,EACdlD,KAAKE,QAAS,EAGdF,KAAK4C,OAGL5C,KAAKwE,UAAU,cAAetB,K,yBAQlC,SAAYuB,GAERzE,KAAKwE,UAAU,cAAeC,K,4BAUlC,SAAeC,EAAUC,EAAMC,GAC3B,IAAMC,EAAQH,EAASG,MAAMF,GAC7B,OAAOE,GAASA,EAAMC,QAAUF,GAAOG,SAASF,EAAMD,GAAM,M,2BAQhE,WAEI,IAAMI,EAAS,CACfA,QAAiB,KACjBA,QAAiB,KACjBA,WAAoB,MAGpB,MAAsB,oBAAXC,QAA2BA,OAAOvE,UAKzCA,UAAUO,iBAEV+D,EAAO5E,QAAU,UACjB4E,EAAOE,QAAUlF,KAAKmF,eAClBzE,UAAU0E,UACV,mBACA,GAEJJ,EAAOK,WAAa,GACbL,GACAtE,UAAUM,oBAEjBgE,EAAO5E,QAAU,SACjB4E,EAAOE,QAAUlF,KAAKmF,eAClBzE,UAAU0E,UACV,wBACA,GAEJJ,EAAOK,WAAa,GACbL,GAEPtE,UAAUC,cACVD,UAAU0E,UAAUP,MAAM,uBAG1BG,EAAO5E,QAAU,OACjB4E,EAAOE,QAAUlF,KAAKmF,eAClBzE,UAAU0E,UACV,qBACA,GAEJJ,EAAOK,WAAa,MACbL,GAEPC,OAAOK,mBACP5E,UAAU0E,UAAUP,MAAM,yBAG1BG,EAAO5E,QAAU,SACjB4E,EAAOK,WAAa,GACpBL,EAAOE,QAAUlF,KAAKmF,eAClBzE,UAAU0E,UACV,uBACA,GAEGJ,IAIXA,EAAO5E,QAAU,2BACV4E,IAtDHA,EAAO5E,QAAU,2BACV4E,Q,gFA9TEnF,G,kCCxCjB0F,EAA2B,GCE/B,IAAIC,EDCJ,SAASC,EAAoBC,GAE5B,IAAIC,EAAeJ,EAAyBG,GAC5C,QAAqBjF,IAAjBkF,EACH,OAAOA,EAAanG,QAGrB,IAAIC,EAAS8F,EAAyBG,GAAY,CAGjDlG,QAAS,IAOV,OAHAoG,EAAoBF,GAAUjG,EAAQA,EAAOD,QAASiG,GAG/ChG,EAAOD,QClBWiG,CAAoB,K,UHO9C","sources":["webpack://WaveSurfer.[name]/webpack/universalModuleDefinition","webpack://WaveSurfer.[name]/./src/plugin/microphone/index.js","webpack://WaveSurfer.[name]/webpack/bootstrap","webpack://WaveSurfer.[name]/webpack/startup"],"sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"WaveSurfer\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"WaveSurfer\"] = factory();\n\telse\n\t\troot[\"WaveSurfer\"] = root[\"WaveSurfer\"] || {}, root[\"WaveSurfer\"][\"microphone\"] = factory();\n})(self, function() {\nreturn ","/**\n * @typedef {Object} MicrophonePluginParams\n * @property {MediaStreamConstraints} constraints The constraints parameter is a\n * MediaStreamConstaints object with two members: video and audio, describing\n * the media types requested. Either or both must be specified.\n * @property {number} bufferSize=4096 The buffer size in units of sample-frames.\n * If specified, the bufferSize must be one of the following values: `256`,\n * `512`, `1024`, `2048`, `4096`, `8192`, `16384`\n * @property {number} numberOfInputChannels=1 Integer specifying the number of\n * channels for this node's input. Values of up to 32 are supported.\n * @property {number} numberOfOutputChannels=1 Integer specifying the number of\n * channels for this node's output.\n * @property {?boolean} deferInit Set to true to manually call\n * `initPlugin('microphone')`\n */\n\n/**\n * Visualize microphone input in a wavesurfer instance.\n *\n * @implements {PluginClass}\n * @extends {Observer}\n * @example\n * // es6\n * import MicrophonePlugin from 'wavesurfer.microphone.js';\n *\n * // commonjs\n * var MicrophonePlugin = require('wavesurfer.microphone.js');\n *\n * // if you are using <script> tags\n * var MicrophonePlugin = window.WaveSurfer.microphone;\n *\n * // ... initialising wavesurfer with the plugin\n * var wavesurfer = WaveSurfer.create({\n *   // wavesurfer options ...\n *   plugins: [\n *     MicrophonePlugin.create({\n *       // plugin options ...\n *     })\n *   ]\n * });\n */\nexport default class MicrophonePlugin {\n    /**\n     * Microphone plugin definition factory\n     *\n     * This function must be used to create a plugin definition which can be\n     * used by wavesurfer to correctly instantiate the plugin.\n     *\n     * @param  {MicrophonePluginParams} params parameters use to initialise the plugin\n     * @return {PluginDefinition} an object representing the plugin\n     */\n    static create(params) {\n        return {\n            name: 'microphone',\n            deferInit: params && params.deferInit ? params.deferInit : false,\n            params: params,\n            instance: MicrophonePlugin\n        };\n    }\n\n    constructor(params, ws) {\n        this.params = params;\n        this.wavesurfer = ws;\n\n        this.active = false;\n        this.paused = false;\n        this.browser = this.detectBrowser();\n        this.reloadBufferFunction = e => this.reloadBuffer(e);\n\n        // cross-browser getUserMedia\n        const promisifiedOldGUM = (\n            constraints,\n            successCallback,\n            errorCallback\n        ) => {\n            // get a hold of getUserMedia, if present\n            const getUserMedia =\n                navigator.getUserMedia ||\n                navigator.webkitGetUserMedia ||\n                navigator.mozGetUserMedia ||\n                navigator.msGetUserMedia;\n            // Some browsers just don't implement it - return a rejected\n            // promise with an error to keep a consistent interface\n            if (!getUserMedia) {\n                return Promise.reject(\n                    new Error('getUserMedia is not implemented in this browser')\n                );\n            }\n            // otherwise, wrap the call to the old navigator.getUserMedia with\n            // a Promise\n            return new Promise((successCallback, errorCallback) => {\n                getUserMedia.call(\n                    navigator,\n                    constraints,\n                    successCallback,\n                    errorCallback\n                );\n            });\n        };\n        // Older browsers might not implement mediaDevices at all, so we set an\n        // empty object first\n        if (navigator.mediaDevices === undefined) {\n            navigator.mediaDevices = {};\n        }\n        // Some browsers partially implement mediaDevices. We can't just assign\n        // an object with getUserMedia as it would overwrite existing\n        // properties. Here, we will just add the getUserMedia property if it's\n        // missing.\n        if (navigator.mediaDevices.getUserMedia === undefined) {\n            navigator.mediaDevices.getUserMedia = promisifiedOldGUM;\n        }\n        this.constraints = this.params.constraints || {\n            video: false,\n            audio: true\n        };\n        this.bufferSize = this.params.bufferSize || 4096;\n        this.numberOfInputChannels = this.params.numberOfInputChannels || 1;\n        this.numberOfOutputChannels = this.params.numberOfOutputChannels || 1;\n\n        this._onBackendCreated = () => {\n            // wavesurfer's AudioContext where we'll route the mic signal to\n            this.micContext = this.wavesurfer.backend.getAudioContext();\n        };\n    }\n\n    init() {\n        this.wavesurfer.on('backend-created', this._onBackendCreated);\n        if (this.wavesurfer.backend) {\n            this._onBackendCreated();\n        }\n    }\n\n    /**\n     * Destroy the microphone plugin.\n     */\n    destroy() {\n        // make sure the buffer is not redrawn during\n        // cleanup and demolition of this plugin.\n        this.paused = true;\n\n        this.wavesurfer.un('backend-created', this._onBackendCreated);\n        this.stop();\n    }\n\n    /**\n     * Allow user to select audio input device, e.g. microphone, and\n     * start the visualization.\n     */\n    start() {\n        navigator.mediaDevices\n            .getUserMedia(this.constraints)\n            .then(data => this.gotStream(data))\n            .catch(data => this.deviceError(data));\n    }\n\n    /**\n     * Pause/resume visualization.\n     */\n    togglePlay() {\n        if (!this.active) {\n            // start it first\n            this.start();\n        } else {\n            // toggle paused\n            this.paused = !this.paused;\n\n            if (this.paused) {\n                this.pause();\n            } else {\n                this.play();\n            }\n        }\n    }\n\n    /**\n     * Play visualization.\n     */\n    play() {\n        this.paused = false;\n\n        this.connect();\n    }\n\n    /**\n     * Pause visualization.\n     */\n    pause() {\n        this.paused = true;\n\n        // disconnect sources so they can be used elsewhere\n        // (eg. during audio playback)\n        this.disconnect();\n    }\n\n    /**\n     * Stop the device stream and remove any remaining waveform drawing from\n     * the wavesurfer canvas.\n     */\n    stop() {\n        if (this.active) {\n            // stop visualization and device\n            this.stopDevice();\n\n            // empty last frame\n            this.wavesurfer.empty();\n        }\n    }\n\n    /**\n     * Stop the device and the visualization.\n     */\n    stopDevice() {\n        this.active = false;\n\n        // stop visualization\n        this.disconnect();\n\n        // stop stream from device\n        if (this.stream && this.stream.getTracks) {\n            this.stream.getTracks().forEach(stream => stream.stop());\n        }\n    }\n\n    /**\n     * Connect the media sources that feed the visualization.\n     */\n    connect() {\n        if (this.stream !== undefined) {\n            // Create a local buffer for data to be copied to the Wavesurfer buffer for Edge\n            if (this.browser.browser === 'edge') {\n                this.localAudioBuffer = this.micContext.createBuffer(\n                    this.numberOfInputChannels,\n                    this.bufferSize,\n                    this.micContext.sampleRate\n                );\n            }\n\n            // Create an AudioNode from the stream.\n            this.mediaStreamSource = this.micContext.createMediaStreamSource(\n                this.stream\n            );\n\n            this.levelChecker = this.micContext.createScriptProcessor(\n                this.bufferSize,\n                this.numberOfInputChannels,\n                this.numberOfOutputChannels\n            );\n            this.mediaStreamSource.connect(this.levelChecker);\n\n            this.levelChecker.connect(this.micContext.destination);\n            this.levelChecker.onaudioprocess = this.reloadBufferFunction;\n        }\n    }\n\n    /**\n     * Disconnect the media sources that feed the visualization.\n     */\n    disconnect() {\n        if (this.mediaStreamSource !== undefined) {\n            this.mediaStreamSource.disconnect();\n        }\n\n        if (this.levelChecker !== undefined) {\n            this.levelChecker.disconnect();\n            this.levelChecker.onaudioprocess = undefined;\n        }\n\n        if (this.localAudioBuffer !== undefined) {\n            this.localAudioBuffer = undefined;\n        }\n    }\n\n    /**\n     * Redraw the waveform.\n     *\n     * @param {object} event Audioprocess event\n     */\n    reloadBuffer(event) {\n        if (!this.paused) {\n            this.wavesurfer.empty();\n\n            if (this.browser.browser === 'edge') {\n                // copy audio data to a local audio buffer,\n                // from https://github.com/audiojs/audio-buffer-utils\n                let channel, l;\n                for (\n                    channel = 0,\n                    l = Math.min(\n                        this.localAudioBuffer.numberOfChannels,\n                        event.inputBuffer.numberOfChannels\n                    );\n                    channel < l;\n                    channel++\n                ) {\n                    this.localAudioBuffer\n                        .getChannelData(channel)\n                        .set(event.inputBuffer.getChannelData(channel));\n                }\n\n                this.wavesurfer.loadDecodedBuffer(this.localAudioBuffer);\n            } else {\n                this.wavesurfer.loadDecodedBuffer(event.inputBuffer);\n            }\n        }\n    }\n\n    /**\n     * Audio input device is ready.\n     *\n     * @param {MediaStream} stream The microphone's media stream.\n     */\n    gotStream(stream) {\n        this.stream = stream;\n        this.active = true;\n\n        // start visualization\n        this.play();\n\n        // notify listeners\n        this.fireEvent('deviceReady', stream);\n    }\n\n    /**\n     * Device error callback.\n     *\n     * @param {string} code Error message\n     */\n    deviceError(code) {\n        // notify listeners\n        this.fireEvent('deviceError', code);\n    }\n\n    /**\n     * Extract browser version out of the provided user agent string.\n     * @param {!string} uastring userAgent string.\n     * @param {!string} expr Regular expression used as match criteria.\n     * @param {!number} pos position in the version string to be returned.\n     * @return {!number} browser version.\n     */\n    extractVersion(uastring, expr, pos) {\n        const match = uastring.match(expr);\n        return match && match.length >= pos && parseInt(match[pos], 10);\n    }\n\n    /**\n     * Browser detector.\n     * @return {object} result containing browser, version and minVersion\n     *     properties.\n     */\n    detectBrowser() {\n        // Returned result object.\n        const result = {};\n        result.browser = null;\n        result.version = null;\n        result.minVersion = null;\n\n        // Non supported browser.\n        if (typeof window === 'undefined' || !window.navigator) {\n            result.browser = 'Not a supported browser.';\n            return result;\n        }\n\n        if (navigator.mozGetUserMedia) {\n            // Firefox\n            result.browser = 'firefox';\n            result.version = this.extractVersion(\n                navigator.userAgent,\n                /Firefox\\/(\\d+)\\./,\n                1\n            );\n            result.minVersion = 31;\n            return result;\n        } else if (navigator.webkitGetUserMedia) {\n            // Chrome/Chromium/Webview/Opera\n            result.browser = 'chrome';\n            result.version = this.extractVersion(\n                navigator.userAgent,\n                /Chrom(e|ium)\\/(\\d+)\\./,\n                2\n            );\n            result.minVersion = 38;\n            return result;\n        } else if (\n            navigator.mediaDevices &&\n            navigator.userAgent.match(/Edge\\/(\\d+).(\\d+)$/)\n        ) {\n            // Edge\n            result.browser = 'edge';\n            result.version = this.extractVersion(\n                navigator.userAgent,\n                /Edge\\/(\\d+).(\\d+)$/,\n                2\n            );\n            result.minVersion = 10547;\n            return result;\n        } else if (\n            window.RTCPeerConnection &&\n            navigator.userAgent.match(/AppleWebKit\\/(\\d+)\\./)\n        ) {\n            // Safari\n            result.browser = 'safari';\n            result.minVersion = 11;\n            result.version = this.extractVersion(\n                navigator.userAgent,\n                /AppleWebKit\\/(\\d+)\\./,\n                1\n            );\n            return result;\n        }\n\n        // Non supported browser default.\n        result.browser = 'Not a supported browser.';\n        return result;\n    }\n}\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// startup\n// Load entry module and return exports\n// This entry module is referenced by other modules so it can't be inlined\nvar __webpack_exports__ = __webpack_require__(872);\n"],"names":["root","factory","exports","module","define","amd","self","MicrophonePlugin","params","ws","this","wavesurfer","active","paused","browser","detectBrowser","reloadBufferFunction","e","reloadBuffer","undefined","navigator","mediaDevices","getUserMedia","constraints","successCallback","errorCallback","webkitGetUserMedia","mozGetUserMedia","msGetUserMedia","Promise","call","reject","Error","video","audio","bufferSize","numberOfInputChannels","numberOfOutputChannels","_onBackendCreated","micContext","backend","getAudioContext","name","deferInit","instance","on","un","stop","then","data","gotStream","catch","deviceError","pause","play","start","connect","disconnect","stopDevice","empty","stream","getTracks","forEach","localAudioBuffer","createBuffer","sampleRate","mediaStreamSource","createMediaStreamSource","levelChecker","createScriptProcessor","destination","onaudioprocess","event","channel","l","Math","min","numberOfChannels","inputBuffer","getChannelData","set","loadDecodedBuffer","fireEvent","code","uastring","expr","pos","match","length","parseInt","result","window","version","extractVersion","userAgent","minVersion","RTCPeerConnection","__webpack_module_cache__","__webpack_exports__","__webpack_require__","moduleId","cachedModule","__webpack_modules__"],"sourceRoot":""}